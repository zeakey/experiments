{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbbb0dde470>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.zeros((10, 10))\n",
    "for i in range(10):\n",
    "    x[:, i] = i\n",
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentProp(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super(RecurrentProp, self).__init__()\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.weight = torch.nn.Parameter(torch.eye(self.input_size))\n",
    "\n",
    "    def forward(self, data):\n",
    "        N, C, H, W = data.shape\n",
    "        assert C == self.input_size, \"%d vs %d\" % (C, self.input_size)\n",
    "        previous = torch.zeros((self.input_size))\n",
    "        # left to right\n",
    "        output0 = torch.tensor(data)\n",
    "        for x in range(1, W):\n",
    "            data1 = output0[:, :, :, x-1]\n",
    "            # N, C, H --> N, H, C\n",
    "            data1 = torch.transpose(data1, 1, 2).contiguous()\n",
    "            data1 = data1.view(-1, self.input_size)\n",
    "            tmp = torch.mm(data1, self.weight)\n",
    "            tmp = torch.reshape(tmp, (N, H, C))\n",
    "            # N, H, C --> N, C, H\n",
    "            tmp = torch.transpose(tmp, 1, 2).contiguous()\n",
    "            output0[:, :, :, x] += tmp\n",
    "        \n",
    "        # right to left\n",
    "        output1 = torch.tensor(data)\n",
    "        for x in range(W-2, -1, -1):\n",
    "            data1 = output1[:, :, :, x+1]\n",
    "            # N, C, H --> N, H, C\n",
    "            data1 = torch.transpose(data1, 1, 2).contiguous()\n",
    "            data1 = data1.view(-1, self.input_size)\n",
    "            tmp = torch.mm(data1, self.weight)\n",
    "            tmp = torch.reshape(tmp, (N, H, C))\n",
    "            # N, H, C --> N, C, H\n",
    "            tmp = torch.transpose(tmp, 1, 2).contiguous()\n",
    "            output1[:, :, :, x] += tmp\n",
    "            \n",
    "        # top down\n",
    "        output2 = torch.tensor(data)\n",
    "        for y in range(1, H):\n",
    "            # data of previous row\n",
    "            data1 = output2[:, :, y-1, :]\n",
    "            # N, C, W --> N, W, C\n",
    "            data1 = torch.transpose(data1, 1, 2).contiguous()\n",
    "            data1 = data1.view(-1, self.input_size)\n",
    "            tmp = torch.mm(data1, self.weight)\n",
    "            tmp = torch.reshape(tmp, (N, H, C))\n",
    "            # N, W, C --> N, C, W\n",
    "            tmp = torch.transpose(tmp, 1, 2).contiguous()\n",
    "            output2[:, :, y, :] += tmp\n",
    "        \n",
    "         # bottom up\n",
    "        output3 = torch.tensor(data)\n",
    "        for y in range(H-2, -1, -1):\n",
    "            # data of previous row\n",
    "            data1 = output3[:, :, y+1, :]\n",
    "            # N, C, W --> N, W, C\n",
    "            data1 = torch.transpose(data1, 1, 2).contiguous()\n",
    "            data1 = data1.view(-1, self.input_size)\n",
    "            tmp = torch.mm(data1, self.weight)\n",
    "            tmp = torch.reshape(tmp, (N, H, C))\n",
    "            # N, W, C --> N, C, W\n",
    "            tmp = torch.transpose(tmp, 1, 2).contiguous()\n",
    "            output3[:, :, y, :] += tmp\n",
    "\n",
    "        return torch.cat((output0, output1, output2, output3), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.recurrent = RecurrentProp(input_size=5, hidden_size=5)\n",
    "    def foward(self, x):\n",
    "        return self.recurrent(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 3\n",
    "model = RecurrentProp(input_size=input_size)\n",
    "\n",
    "x = torch.ones((1, input_size, 5, 5))\n",
    "output = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 2., 3., 4., 5.],\n",
       "          [1., 2., 3., 4., 5.],\n",
       "          [1., 2., 3., 4., 5.],\n",
       "          [1., 2., 3., 4., 5.],\n",
       "          [1., 2., 3., 4., 5.]],\n",
       "\n",
       "         [[1., 2., 3., 4., 5.],\n",
       "          [1., 2., 3., 4., 5.],\n",
       "          [1., 2., 3., 4., 5.],\n",
       "          [1., 2., 3., 4., 5.],\n",
       "          [1., 2., 3., 4., 5.]],\n",
       "\n",
       "         [[1., 2., 3., 4., 5.],\n",
       "          [1., 2., 3., 4., 5.],\n",
       "          [1., 2., 3., 4., 5.],\n",
       "          [1., 2., 3., 4., 5.],\n",
       "          [1., 2., 3., 4., 5.]],\n",
       "\n",
       "         [[5., 4., 3., 2., 1.],\n",
       "          [5., 4., 3., 2., 1.],\n",
       "          [5., 4., 3., 2., 1.],\n",
       "          [5., 4., 3., 2., 1.],\n",
       "          [5., 4., 3., 2., 1.]],\n",
       "\n",
       "         [[5., 4., 3., 2., 1.],\n",
       "          [5., 4., 3., 2., 1.],\n",
       "          [5., 4., 3., 2., 1.],\n",
       "          [5., 4., 3., 2., 1.],\n",
       "          [5., 4., 3., 2., 1.]],\n",
       "\n",
       "         [[5., 4., 3., 2., 1.],\n",
       "          [5., 4., 3., 2., 1.],\n",
       "          [5., 4., 3., 2., 1.],\n",
       "          [5., 4., 3., 2., 1.],\n",
       "          [5., 4., 3., 2., 1.]],\n",
       "\n",
       "         [[1., 1., 1., 1., 1.],\n",
       "          [2., 2., 2., 2., 2.],\n",
       "          [3., 3., 3., 3., 3.],\n",
       "          [4., 4., 4., 4., 4.],\n",
       "          [5., 5., 5., 5., 5.]],\n",
       "\n",
       "         [[1., 1., 1., 1., 1.],\n",
       "          [2., 2., 2., 2., 2.],\n",
       "          [3., 3., 3., 3., 3.],\n",
       "          [4., 4., 4., 4., 4.],\n",
       "          [5., 5., 5., 5., 5.]],\n",
       "\n",
       "         [[1., 1., 1., 1., 1.],\n",
       "          [2., 2., 2., 2., 2.],\n",
       "          [3., 3., 3., 3., 3.],\n",
       "          [4., 4., 4., 4., 4.],\n",
       "          [5., 5., 5., 5., 5.]],\n",
       "\n",
       "         [[5., 5., 5., 5., 5.],\n",
       "          [4., 4., 4., 4., 4.],\n",
       "          [3., 3., 3., 3., 3.],\n",
       "          [2., 2., 2., 2., 2.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       "\n",
       "         [[5., 5., 5., 5., 5.],\n",
       "          [4., 4., 4., 4., 4.],\n",
       "          [3., 3., 3., 3., 3.],\n",
       "          [2., 2., 2., 2., 2.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       "\n",
       "         [[5., 5., 5., 5., 5.],\n",
       "          [4., 4., 4., 4., 4.],\n",
       "          [3., 3., 3., 3., 3.],\n",
       "          [2., 2., 2., 2., 2.],\n",
       "          [1., 1., 1., 1., 1.]]]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 9, 8, 7, 6, 5, 4, 3, 2]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10, 1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
